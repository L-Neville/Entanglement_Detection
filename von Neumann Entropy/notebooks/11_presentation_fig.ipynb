{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, transpile, assemble\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Pauli, Operator, random_statevector, partial_trace, random_clifford\n",
    "from qiskit_aer import AerSimulator, Aer\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "from winsound import Beep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. General Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def alias_setup(probabilities):\n",
    "    n = len(probabilities)\n",
    "    prob = [0] * n\n",
    "    alias = [0] * n\n",
    "\n",
    "    # Normalize the probabilities\n",
    "    scaled_prob = [p * n for p in probabilities]\n",
    "\n",
    "    # Create two lists to track small and large probabilities\n",
    "    small = []\n",
    "    large = []\n",
    "\n",
    "    for i, sp in enumerate(scaled_prob):\n",
    "        if sp < 1.0:\n",
    "            small.append(i)\n",
    "        else:\n",
    "            large.append(i)\n",
    "\n",
    "    # Process the small and large lists\n",
    "    while small and large:\n",
    "        small_index = small.pop()\n",
    "        large_index = large.pop()\n",
    "\n",
    "        prob[small_index] = scaled_prob[small_index]\n",
    "        alias[small_index] = large_index\n",
    "\n",
    "        scaled_prob[large_index] = (scaled_prob[large_index] + scaled_prob[small_index]) - 1.0\n",
    "\n",
    "        if scaled_prob[large_index] < 1.0:\n",
    "            small.append(large_index)\n",
    "        else:\n",
    "            large.append(large_index)\n",
    "\n",
    "    # Fill remaining probabilities\n",
    "    for i in large:\n",
    "        prob[i] = 1.0\n",
    "    for i in small:\n",
    "        prob[i] = 1.0\n",
    "\n",
    "    return prob, alias\n",
    "\n",
    "def alias_sample(prob, alias):\n",
    "    n = len(prob)\n",
    "    i = random.randint(0, n - 1)\n",
    "    r = random.random()\n",
    "    if r < prob[i]:\n",
    "        return i\n",
    "    else:\n",
    "        return alias[i]\n",
    "\n",
    "# Example usage\n",
    "probabilities = [0.1, 0.3, 0.4, 0.2]\n",
    "prob, alias = alias_setup(probabilities)\n",
    "\n",
    "# Sample from the distribution\n",
    "sampled_index = alias_sample(prob, alias)\n",
    "print(sampled_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_prod(*tensors):\n",
    "    if len(tensors) == 2:\n",
    "        return np.kron(tensors[0], tensors[1])\n",
    "    else:\n",
    "        return np.kron(tensors[0], tensor_prod(*tensors[1:]))\n",
    "    \n",
    "def hermitian(matrix):\n",
    "    return np.allclose(matrix, matrix.conj().T)\n",
    "\n",
    "def trace_one(matrix):\n",
    "    return np.isclose(np.trace(matrix), 1)\n",
    "\n",
    "def positive_semi_definite(matrix, tol=1e-8):\n",
    "    return np.all(np.linalg.eigvals(matrix) + tol >= 0)\n",
    "\n",
    "def is_legal(matrix):\n",
    "    return hermitian(matrix) and trace_one(matrix) and positive_semi_definite(matrix)\n",
    "\n",
    "def int_to_bin_list(n, length):\n",
    "    bin_list = np.zeros(length)\n",
    "    bin_list[n] = 1\n",
    "    return bin_list\n",
    "\n",
    "def expand_to_tensor_product(array):\n",
    "    index = np.argmax(array)\n",
    "    n = int(np.log2(len(array)))\n",
    "    binary_string = format(index, f'0{n}b')\n",
    "    tensor_product = []\n",
    "    for bit in binary_string:\n",
    "        if bit == '0':\n",
    "            tensor_product.append(np.array([1, 0]))\n",
    "        else:\n",
    "            tensor_product.append(np.array([0, 1]))\n",
    "    return tensor_product\n",
    "\n",
    "def single_sample(prob_list):\n",
    "    assert np.isclose(sum(prob_list), 1), \"probability does not sum up to 1\"\n",
    "    # rd = np.random.random()\n",
    "    # inf, sup = 0, 0\n",
    "    # for i, e in enumerate(prob_list):\n",
    "    #     sup += e\n",
    "    #     if inf <= rd <= sup:\n",
    "    #         return i\n",
    "    #     else:\n",
    "    #         inf = sup\n",
    "    # raise ValueError(\"random value does not meet any interval\")\n",
    "    return alias_sample(*alias_setup(prob_list))\n",
    "\n",
    "def split_and_calculate_mean(values, group_size):\n",
    "    groups = [values[i:i + group_size] for i in range(0, len(values), group_size)]\n",
    "    means = [np.sum(group, axis=0) / len(group) for group in groups]\n",
    "    return means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classical Shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumState():\n",
    "    def __init__(self, num_qubits:int, num_shots:int|list, batch_size:int|list, pauli_observables:list, purity:bool, veri:bool, meas:str):\n",
    "        assert meas in ['Clifford', 'Pauli', 'direct'], 'unrecognized measurement pattern, use either Clifford, Pauli, or direct'\n",
    "        self._num_qubits = num_qubits\n",
    "        self._observables = pauli_observables\n",
    "        self._compute_purity = purity\n",
    "        self._batch_size = batch_size\n",
    "        self._num_shots = num_shots\n",
    "        self._veri = veri\n",
    "        self._meas = meas\n",
    "        self._dm = None\n",
    "        self._entangled = None\n",
    "        \n",
    "    @property\n",
    "    def dm(self):\n",
    "        return self._dm\n",
    "    \n",
    "    @dm.setter\n",
    "    def dm(self, new_dm):\n",
    "        if not (self._veri or is_legal(new_dm)):\n",
    "            raise ValueError(\"density matrix is not physical\")\n",
    "        else:\n",
    "            self._dm = new_dm\n",
    "    \n",
    "    def set_dm(self):\n",
    "        raise NotImplementedError(\"without information to construct density matrix\")\n",
    "    \n",
    "    def random_evolve(self):\n",
    "        if self._meas == 'Clifford':\n",
    "            self._U = random_clifford(self._num_qubits).to_matrix()\n",
    "            self._dm = self._U @ self.dm @ np.conj(self._U).T\n",
    "        elif self._meas == 'Pauli':\n",
    "            self._U = [random_clifford(1).to_matrix() for _ in range(self._num_qubits)]\n",
    "            self._dm = tensor_prod(*self._U) @ self.dm @ np.conj(tensor_prod(*self._U)).T\n",
    "    \n",
    "    def single_shot_measure(self):\n",
    "        prob_list = [self._dm[i, i] for i in range(2 ** self._num_qubits)]\n",
    "        single_shot_state = int_to_bin_list(single_sample(prob_list), 2 ** self._num_qubits)\n",
    "        del self._dm\n",
    "        if self._meas == 'Clifford':\n",
    "            self._state = single_shot_state\n",
    "        elif self._meas == 'Pauli':\n",
    "            self._state = expand_to_tensor_product(single_shot_state)\n",
    "    \n",
    "    def reconstruct_dm(self):\n",
    "        dim = 2 ** self._num_qubits\n",
    "        if self._meas == 'Clifford':\n",
    "            return (dim + 1) * (np.conj(self._U).T @ np.outer(self._state, self._state) @ self._U) - np.eye(dim)\n",
    "        elif self._meas == 'Pauli':\n",
    "            return tensor_prod(*[3 * (np.conj(single_U).T @ np.outer(single_state, single_state) @ single_U) - np.eye(2) \n",
    "                                 for single_U, single_state in zip(self._U, self._state)])\n",
    "\n",
    "    # def classical_shadow(self):\n",
    "    #     shadows = {obs: [] for obs in self._observables}\n",
    "    #     temp_shadows = {obs: [] for obs in self._observables}\n",
    "    #     dm_copy = self._dm\n",
    "    #     for _ in range(self._num_shots // self._batch_size):\n",
    "    #         for _ in range(self._batch_size):\n",
    "    #             self._dm = dm_copy\n",
    "    #             self.random_evolve()\n",
    "    #             self.single_shot_measure()\n",
    "    #             rdm = self.reconstruct_dm()\n",
    "    #             for k, v in temp_shadows.items():\n",
    "    #                 v.append(np.trace(Pauli(k).to_matrix() @ rdm))\n",
    "    #         for k, v in shadows.items():\n",
    "    #             v.append(np.mean(temp_shadows[k]))\n",
    "    #         temp_shadows = {obs: [] for obs in self._observables}\n",
    "    #     del temp_shadows\n",
    "    #     return {k: np.median(v) for k, v in shadows.items()}\n",
    "    \n",
    "    def classical_shadow(self):\n",
    "        assert self._meas in ['Clifford', 'Pauli'], 'only Clifford and Pauli pattern have classical_shadow method'\n",
    "        if not self._compute_purity:\n",
    "            shadows = {obs: [] for obs in self._observables}\n",
    "            dm_copy = self._dm\n",
    "            for _ in range(self._num_shots // self._batch_size):\n",
    "                snapshots = []\n",
    "                for _ in range(self._batch_size):\n",
    "                    self._dm = dm_copy\n",
    "                    self.random_evolve()\n",
    "                    self.single_shot_measure()\n",
    "                    snapshots.append(self.reconstruct_dm())\n",
    "                mean = np.mean(np.stack(snapshots), axis=0)\n",
    "                for k, v in shadows.items():\n",
    "                    v.append(np.trace(Pauli(k).to_matrix() @ mean).real)\n",
    "            return {k: np.median(v) for k, v in shadows.items()}\n",
    "        else:\n",
    "            dm_copy = self._dm\n",
    "            snapshots = []\n",
    "            max_shots = np.max(self._num_shots)\n",
    "            for _ in range(max_shots):\n",
    "                self._dm = dm_copy\n",
    "                self.random_evolve()\n",
    "                self.single_shot_measure()\n",
    "                snapshots.append(self.reconstruct_dm())\n",
    "            purities = []   \n",
    "            for num_shots in self._num_shots:\n",
    "                temp_snapshots = snapshots[:num_shots]\n",
    "                mean = np.mean(np.stack(temp_snapshots), axis=0)\n",
    "                purities.append(np.trace(mean @ mean).real)\n",
    "            return purities\n",
    "        \n",
    "    def quantum_state_tomography_for_purity(self):\n",
    "        max_shots = np.max(self._num_shots)\n",
    "        max_repetition = max_shots // (4 ** self._num_qubits)\n",
    "        all_observables = [''.join(obsv) for obsv in list(itertools.product(*['IXYZ' for _ in range(self._num_qubits)]))]\n",
    "        \n",
    "        def pm1_sample(expct, num_samples):\n",
    "            prob_p1 = (1 + expct) / 2\n",
    "            return [+1 if np.random.random() < prob_p1 else -1 for _ in range(num_samples)]\n",
    "        \n",
    "        all_samples = dict()\n",
    "        for obsv in all_observables:\n",
    "            all_samples[obsv] = pm1_sample(np.trace(self._dm @ Pauli(obsv).to_matrix()).real, max_repetition)\n",
    "        purities = []\n",
    "        for num_shots in self._num_shots:\n",
    "            repetition = num_shots // (4 ** self._num_qubits)\n",
    "            temp_samples = {k: v[:repetition] for k, v in all_samples.items()}\n",
    "            estm_dm = np.sum(np.stack([np.mean(new_v) * Pauli(k).to_matrix() for k, new_v in temp_samples.items()]), axis=0) / (2 ** self._num_qubits)\n",
    "            purities.append(np.trace(estm_dm @ estm_dm).real)\n",
    "        return purities\n",
    "    \n",
    "    def classical_shadow_multi_batches(self):\n",
    "        assert self._meas in ['Clifford', 'Pauli'], 'only Clifford and Pauli pattern have classical_shadow method'\n",
    "        assert isinstance(self._batch_size, list) or isinstance(self._batch_size, np.ndarray), 'there must be more than one batch size'\n",
    "        if not self._compute_purity:\n",
    "            all_shadows = [{obs: [] for obs in self._observables} for _ in self._batch_size]\n",
    "            dm_copy = self._dm\n",
    "            snapshots = []\n",
    "            for _ in range(self._num_shots):\n",
    "                self._dm = dm_copy\n",
    "                self.random_evolve()\n",
    "                self.single_shot_measure()\n",
    "                snapshots.append(self.reconstruct_dm())\n",
    "            for index, size in enumerate(self._batch_size):\n",
    "                snapshots = split_and_calculate_mean(snapshots, size)\n",
    "                for k in self._observables:\n",
    "                    samples = [np.trace(snapshot @ Pauli(k).to_matrix()).real for snapshot in snapshots]\n",
    "                    all_shadows[index][k] = np.median(samples)\n",
    "            return all_shadows\n",
    "    \n",
    "    def direct_sample(self):\n",
    "        assert self._meas == 'direct', 'only direct pattern have classical_shadow method'\n",
    "        all_samples = {obs: [] for obs in self._observables}\n",
    "        repetition = self._num_shots // len(self._observables)\n",
    "        for k in all_samples.keys():\n",
    "            expct = np.trace(Pauli(k).to_matrix() @ self._dm).real\n",
    "            prob_p1 = (1 + expct) / 2\n",
    "            prob_m1 = (1 - expct) / 2\n",
    "            all_samples[k] = [+1 if np.random.random() < prob_p1 else -1 for _ in range(repetition)]\n",
    "            all_samples[k] = np.mean(all_samples[k])\n",
    "        return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prob_lst(num_states):\n",
    "    prob_lst = np.array([np.random.random() for _ in range(num_states)])\n",
    "    prob_lst /= np.sum(prob_lst)\n",
    "    return prob_lst\n",
    "\n",
    "def generate_dm(num_qubits, num_states, state_lst=None, prob_lst=None, prime_prob=None):\n",
    "    assert (prob_lst is None) or (prime_prob is None), 'cannot set prob_lst and prime_prob together'\n",
    "    if state_lst is None:\n",
    "        state_lst = [random_statevector(2**num_qubits) for _ in range(num_states)]\n",
    "    if prime_prob is not None:\n",
    "        prob_lst = np.array([prime_prob] + (generate_prob_lst(num_states - 1) * (1 - prime_prob)).tolist())\n",
    "    elif prob_lst is None:\n",
    "        prob_lst = generate_prob_lst(num_states)\n",
    "    density_matrix = sum([DensityMatrix(state_lst[i]).data * prob_lst[i] for i in range(num_states)])\n",
    "    return density_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state = generate_dm(4, 8, prime_prob=.8)\n",
    "\n",
    "observables = np.random.choice([''.join(obsv) for obsv in list(itertools.product(*['IXYZ' for _ in range(4)]))], size=256, replace=False)\n",
    "qstate_c = QuantumState(4, 50000, [50, 250, 1000, 5000], observables, False, 'Clifford')\n",
    "qstate_p = QuantumState(4, 50000, [50, 250, 1000, 5000], observables, False, 'Pauli')\n",
    "qstate_d = QuantumState(4, 50000, 0, observables, False, 'direct')\n",
    "qstate_c.dm, qstate_p.dm, qstate_d.dm = state, state, state\n",
    "\n",
    "dict_th = {k: np.trace(Pauli(k).to_matrix() @ state).real for k in observables}\n",
    "lst_dict_c = qstate_c.classical_shadow_multi_batches()\n",
    "lst_dict_p = qstate_p.classical_shadow_multi_batches()\n",
    "dict_d = qstate_d.direct_sample()\n",
    "df = pd.DataFrame([dict_th, *lst_dict_c, *lst_dict_p, dict_d])\n",
    "df.index = ['theoretical', 'Clifford-50', 'Clifford-250', 'Clifford-1000', 'Clifford-5000'\n",
    "            , 'Pauli-50', 'Pauli-250', 'Pauli-1000', 'Pauli-5000', 'direct']\n",
    "df.to_json('cs2.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ['theoretical', 'Clifford-50', 'Clifford-250', 'Clifford-1000', 'Clifford-5000'\n",
    "            , 'Pauli-50', 'Pauli-250', 'Pauli-1000', 'Pauli-5000', 'direct']\n",
    "df.to_json('cs1.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_cols = np.random.choice(observables, size=64, replace=False)\n",
    "selected_indices = ['theoretical', 'Clifford-5000', 'Pauli-5000', 'direct'] \n",
    "df_selected = df.loc[selected_indices, selected_cols]\n",
    "\n",
    "df_transposed = df_selected.T\n",
    "df_sorted = df_transposed.sort_values(by='theoretical')\n",
    "# df_sorted = df_sorted.T\n",
    "\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(18, 10))  # Adjusted to a more typical size\n",
    "\n",
    "# Plot each series with lines and scatter points\n",
    "for index in df_sorted.columns:\n",
    "    if index == 'theoretical':\n",
    "        plt.plot(df_sorted.index, df_sorted[index], label=index, color='black')\n",
    "    else:\n",
    "        plt.scatter(df_sorted.index, df_sorted[index], label=index)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Classical Shadow v.s. Direct Sampling')\n",
    "plt.xlabel('Observables')\n",
    "plt.ylabel('Expectation')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('cs01.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_values = df.loc['theoretical'].values\n",
    "c_esti_values = df.loc['Clifford-5000'].values\n",
    "p_esti_values = df.loc['Pauli-5000'].values\n",
    "d_esti_values = df.loc['direct'].values\n",
    "filtered_indices = np.abs(th_values) > .1\n",
    "th_values = th_values[filtered_indices]\n",
    "c_esti_values = c_esti_values[filtered_indices]\n",
    "p_esti_values = p_esti_values[filtered_indices]\n",
    "d_esti_values = d_esti_values[filtered_indices]\n",
    "\n",
    "print(f\"Clifford: {np.mean(np.sort(np.abs((c_esti_values - th_values) / th_values))[:240])}\")\n",
    "print(f\"Pauli: {np.mean(np.sort(np.abs((p_esti_values - th_values) / th_values))[:240])}\")\n",
    "print(f\"direct: {np.mean(np.sort(np.abs((d_esti_values - th_values) / th_values))[:240])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = generate_dm(5, 4, prime_prob=.8)\n",
    "observables = np.random.choice([''.join(obsv) for obsv in list(itertools.product(*['IXYZ' for _ in range(5)]))], size=8, replace=False)\n",
    "qstate_d = QuantumState(5, 10000, 50, observables, False, 'Clifford')\n",
    "qstate_d.dm = state\n",
    "qstate_d.classical_shadow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state = generate_dm(4, 8, prime_prob=.8)\n",
    "shots = list(np.linspace(100, 1000, 10)) + list(np.linspace(2000, 10000, 9)) + list(np.linspace(20000, 100000, 9))\n",
    "shots = [int(shot) for shot in shots]\n",
    "\n",
    "# observables = np.random.choice([''.join(obsv) for obsv in list(itertools.product(*['IXYZ' for _ in range(4)]))], size=256, replace=False)\n",
    "qstate_c = QuantumState(4, shots, [], [], True, False, 'Clifford')\n",
    "qstate_p = QuantumState(4, shots, [], [], True, False, 'Pauli')\n",
    "qstate_d = QuantumState(4, shots, [], [], True, False, 'direct')\n",
    "qstate_c.dm, qstate_p.dm, qstate_d.dm = state, state, state\n",
    "lst_c = qstate_c.classical_shadow()\n",
    "lst_p = qstate_p.classical_shadow()\n",
    "lst_d = qstate_d.quantum_state_tomography_for_purity()\n",
    "true_purity = np.trace(state @ state).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = list(np.linspace(100, 1000, 10)) + list(np.linspace(2000, 10000, 9)) + list(np.linspace(20000, 100000, 9))\n",
    "shots = [int(shot) for shot in shots]\n",
    "qstate_d = QuantumState(4, shots, [], [], True, False, 'direct')\n",
    "qstate_d.dm = state\n",
    "lst_d = qstate_d.quantum_state_tomography_for_purity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure size\n",
    "# plt.figure(figsize=(18, ))  # Adjusted to a more typical size\n",
    "\n",
    "# Plot each series with lines and scatter points\n",
    "plt.plot(shots[10:], [true_purity] * len(shots[10:]), linestyle='--', label='theoretical')\n",
    "plt.plot(shots[10:], lst_c[10:], label='Clifford')\n",
    "plt.scatter(shots[10:], lst_c[10:], color='orange')\n",
    "plt.plot(shots[10:], lst_p[10:], label='Pauli')\n",
    "plt.scatter(shots[10:], lst_p[10:], color='green')\n",
    "plt.plot(shots[10:], lst_d[10:], label='direct')\n",
    "plt.scatter(shots[10:], lst_d[10:], color='red')\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Classical Shadow v.s. Direct Sampling')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Num. of Shots')\n",
    "plt.ylabel('Purity Predicted')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('cs02-1.png', dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compressed Sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = generate_dm(5, 32, prime_prob=.95)\n",
    "purity = np.trace(rho @ rho).real\n",
    "purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_Pauli_strings(num_strings, num_qubits, pattern='balanced'):\n",
    "    assert pattern in ['balanced', 'pro_I', 'pro_XYZ', 'uv_pair'], 'please choose pattern from: balanced, pro_I, pro_XYZ, uv_pair'\n",
    "    generated_strings = []\n",
    "    characters = ['X', 'Y', 'Z', 'I']\n",
    "    assert 0 < num_strings <= 4 ** num_qubits - 1, 'too much or too few strings to generate'\n",
    "    if pattern == 'balanced':\n",
    "        for _ in range(num_strings):\n",
    "            while True:\n",
    "                random_string = ''.join(np.random.choice(characters) for _ in range(num_qubits))\n",
    "                if random_string != 'I' * num_qubits and random_string not in generated_strings:\n",
    "                    generated_strings.append(random_string)\n",
    "                    break\n",
    "        return generated_strings\n",
    "    if pattern == 'uv_pair':\n",
    "        uv_map = {'00':'I', '01':'Z', '10':'X', '11':'Y'}\n",
    "        whole, remain = num_strings // 2 ** (num_qubits), num_strings % 2 ** (num_qubits)\n",
    "        if whole > 0:\n",
    "            v_lst = [format(i, f'0{num_qubits}b') for i in range(2 ** num_qubits)]\n",
    "            u_lst = np.random.choice([format(i, f'0{num_qubits}b') for i in range(1, 2 ** num_qubits)], whole, replace=False).tolist()\n",
    "            for u, v in list(itertools.product(u_lst, v_lst)):\n",
    "                generated_strings.append(''.join([uv_map[u_char + v_char] for u_char, v_char in zip(u, v)]))\n",
    "        if remain > 0:\n",
    "            u_lst = ['0' * num_qubits]\n",
    "            v_lst = np.random.choice([format(i, f'0{num_qubits}b') for i in range(1, 2 ** num_qubits)], remain, replace=False).tolist()\n",
    "            for u, v in list(itertools.product(u_lst, v_lst)):\n",
    "                generated_strings.append(''.join([uv_map[u_char + v_char] for u_char, v_char in zip(u, v)]))\n",
    "        return generated_strings\n",
    "    all_strings = generate_random_Pauli_strings(4 ** num_qubits - 1, num_qubits, pattern='balanced')\n",
    "    grouped = dict()\n",
    "    for i in range(num_qubits):\n",
    "        grouped[i] = []\n",
    "    for string in all_strings:\n",
    "        grouped[string.count('I')].append(string)\n",
    "    if pattern == 'pro_I':\n",
    "        i = num_qubits - 1\n",
    "        while len(generated_strings) < num_strings:\n",
    "            if num_strings - len(generated_strings) >= len(grouped[i]):\n",
    "                generated_strings += grouped[i]\n",
    "            else:\n",
    "                generated_strings += np.random.choice(grouped[i], num_strings - len(generated_strings), replace=True).tolist()\n",
    "            i -= 1\n",
    "        return generated_strings\n",
    "    if pattern == 'pro_XYZ':\n",
    "        i = 0\n",
    "        while len(generated_strings) < num_strings:\n",
    "            if num_strings - len(generated_strings) >= len(grouped[i]):\n",
    "                generated_strings += grouped[i]\n",
    "            else:\n",
    "                generated_strings += np.random.choice(grouped[i], num_strings - len(generated_strings), replace=True).tolist()\n",
    "            i += 1\n",
    "        return generated_strings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fidelity(dm1, dm2, tol=1e-5):\n",
    "    # assert is_legal(dm1) and is_legal(dm2), 'inputs are not legal density matrices'\n",
    "    if not is_legal(dm1) and is_legal(dm2):\n",
    "        print(\"Warning: inputs are not legal density matrices\")\n",
    "    try: \n",
    "        fidelity = (np.trace(sqrtm(sqrtm(dm1) @ dm2 @ sqrtm(dm1)))) ** 2\n",
    "    except ValueError:\n",
    "        print('fidelity cannot be computed for given inputs')\n",
    "    assert np.abs(np.imag(fidelity)) < tol, 'fidelity is not real within tol'\n",
    "    return fidelity.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(dim, obsv, expct, tol=1e-5):\n",
    "    sigma = cp.Variable((dim, dim), complex=True)\n",
    "    objective = cp.Minimize(cp.abs(5 * cp.norm(sigma, 'nuc') + 0 * cp.norm(sigma, 'fro') ** 2))\n",
    "    constraints = [cp.trace(sigma) == 1]\n",
    "    for o, e in zip(obsv, expct):\n",
    "        constraints.append(cp.abs(cp.trace(sigma @ Pauli(o).to_matrix()) - e) <= tol)\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    print(problem.status)\n",
    "    return sigma.value\n",
    "\n",
    "def estimate_Pauli_expectations(dm, obsv, num_samples, simulation=False):\n",
    "    num_samples = int(num_samples)\n",
    "    if simulation: # simulate the process of sampling\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        prob_p1 = (1 + exp) / 2\n",
    "        prob_m1 = 1 - prob_p1\n",
    "        samples = np.random.choice([+1, -1], size=num_samples, p=[prob_p1, prob_m1])\n",
    "        return np.mean(samples)\n",
    "    else: # use the approximate distribution instead\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        num_samples_root = num_samples ** .5\n",
    "        std_dev = (1 - exp ** 2) ** .5 / num_samples_root\n",
    "        return np.random.normal(exp, std_dev)\n",
    "    \n",
    "num_qubits = 5\n",
    "d = 2 ** num_qubits\n",
    "nums_observables = [100, 300, 500, 700]\n",
    "fidelities = dict()\n",
    "for num_observables in nums_observables:\n",
    "    print(num_observables)\n",
    "    fidelities[num_observables] = []\n",
    "    for i in range(4):\n",
    "        print('    ' + str(i))\n",
    "        observables = generate_random_Pauli_strings(300, 5, 'balanced')\n",
    "        expectations = [estimate_Pauli_expectations(rho, obsv, 10e6) for obsv in observables]\n",
    "        sigma = optimize(d, observables, expectations)\n",
    "        fidelities[num_observables].append(get_fidelity(sigma, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(dim, obsv, expct, tol=1e-5):\n",
    "    sigma = cp.Variable((dim, dim), complex=True)\n",
    "    objective = cp.Minimize(cp.abs(5 * cp.norm(sigma, 'nuc') + 0 * cp.norm(sigma, 'fro') ** 2))\n",
    "    constraints = [cp.trace(sigma) == 1]\n",
    "    for o, e in zip(obsv, expct):\n",
    "        constraints.append(cp.abs(cp.trace(sigma @ Pauli(o).to_matrix()) - e) <= tol)\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    print(problem.status)\n",
    "    return sigma.value\n",
    "\n",
    "def estimate_Pauli_expectations(dm, obsv, num_samples, simulation=False):\n",
    "    num_samples = int(num_samples)\n",
    "    if simulation: # simulate the process of sampling\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        prob_p1 = (1 + exp) / 2\n",
    "        prob_m1 = 1 - prob_p1\n",
    "        samples = np.random.choice([+1, -1], size=num_samples, p=[prob_p1, prob_m1])\n",
    "        return np.mean(samples)\n",
    "    else: # use the approximate distribution instead\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        num_samples_root = num_samples ** .5\n",
    "        std_dev = (1 - exp ** 2) ** .5 / num_samples_root\n",
    "        return np.random.normal(exp, std_dev)\n",
    "    \n",
    "num_qubits = 5\n",
    "d = 2 ** num_qubits\n",
    "nums_observables = [30, 50, 70, 90]\n",
    "fidelities = dict()\n",
    "for num_observables in nums_observables:\n",
    "    print(num_observables)\n",
    "    fidelities[num_observables] = []\n",
    "    for i in range(4):\n",
    "        print('    ' + str(i))\n",
    "        observables = generate_random_Pauli_strings(300, 5, 'balanced')\n",
    "        expectations = [estimate_Pauli_expectations(rho, obsv, 10e6) for obsv in observables]\n",
    "        sigma = optimize(d, observables, expectations)\n",
    "        fidelities[num_observables].append(get_fidelity(sigma, rho))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
