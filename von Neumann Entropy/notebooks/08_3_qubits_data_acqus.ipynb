{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, transpile, assemble\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Pauli, Operator, random_statevector, partial_trace\n",
    "from qiskit_aer import AerSimulator, Aer\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "from winsound import Beep\n",
    "\n",
    "def tensor_prod(*tensors):\n",
    "    if len(tensors) == 2:\n",
    "        return np.kron(tensors[0], tensors[1])\n",
    "    else:\n",
    "        return np.kron(tensors[0], tensor_prod(*tensors[1:]))\n",
    "    \n",
    "def hermitian(matrix):\n",
    "    return np.allclose(matrix, matrix.conj().T)\n",
    "\n",
    "def trace_one(matrix):\n",
    "    return np.isclose(np.trace(matrix), 1)\n",
    "\n",
    "def positive_semi_definite(matrix, tol=1e-8):\n",
    "    return np.all(np.linalg.eigvals(matrix) + tol >= 0)\n",
    "\n",
    "def is_legal(matrix):\n",
    "    return hermitian(matrix) and trace_one(matrix) and positive_semi_definite(matrix)\n",
    "\n",
    "def check_legal(matrix, print_errors=True):\n",
    "    errors, legal = [], True\n",
    "    if not hermitian(matrix):\n",
    "        errors.append('not hermitian')\n",
    "    if not trace_one(matrix):\n",
    "        errors.append('trace not equal to one')\n",
    "    if not positive_semi_definite(matrix):\n",
    "        errors.append('not positive semidefinite')\n",
    "    if len(errors) > 0:\n",
    "        legal = False\n",
    "    if print_errors:\n",
    "        if not legal:\n",
    "            print(f'input is not legal: ' + '; '.join(errors))\n",
    "        else: \n",
    "            print('input is a legal density matrix')\n",
    "    return legal\n",
    "        \n",
    "        \n",
    "def generate_prob_lst(num_states):\n",
    "    prob_lst = np.array([np.random.random() for _ in range(num_states)])\n",
    "    prob_lst /= np.sum(prob_lst)\n",
    "    return prob_lst\n",
    "\n",
    "def get_rank(dm, tol=1e-10):\n",
    "    return int(np.sum(np.linalg.eigvalsh(dm) > tol))\n",
    "\n",
    "def get_fidelity(dm1, dm2, tol=1e-5):\n",
    "    # assert is_legal(dm1) and is_legal(dm2), 'inputs are not legal density matrices'\n",
    "    if not is_legal(dm1) and is_legal(dm2):\n",
    "        print(\"Warning: inputs are not legal density matrices\")\n",
    "    try: \n",
    "        fidelity = (np.trace(sqrtm(sqrtm(dm1) @ dm2 @ sqrtm(dm1)))) ** 2\n",
    "    except ValueError:\n",
    "        print('fidelity cannot be computed for given inputs')\n",
    "    assert np.abs(np.imag(fidelity)) < tol, 'fidelity is not real within tol'\n",
    "    return fidelity.real\n",
    "\n",
    "def generate_dm(num_qubits, num_states, state_lst=None, prob_lst=None, prime_prob=None, compute_fidelity=False):\n",
    "    assert (prob_lst is None) or (prime_prob is None), 'cannot set prob_lst and prime_prob together'\n",
    "    if state_lst is None:\n",
    "        state_lst = [random_statevector(2**num_qubits) for _ in range(num_states)]\n",
    "        if compute_fidelity:\n",
    "            prime_state = DensityMatrix(state_lst[0]).data\n",
    "    if prime_prob is not None:\n",
    "        prob_lst = np.array([prime_prob] + (generate_prob_lst(num_states - 1) * (1 - prime_prob)).tolist())\n",
    "    elif prob_lst is None:\n",
    "        prob_lst = generate_prob_lst(num_states)\n",
    "    density_matrix = sum([DensityMatrix(state_lst[i]).data * prob_lst[i] for i in range(num_states)])\n",
    "    if compute_fidelity:\n",
    "        fidelity = get_fidelity(prime_state, density_matrix)\n",
    "        return density_matrix, fidelity\n",
    "    else:\n",
    "        return density_matrix\n",
    "\n",
    "def generate_random_Pauli_strings(num_strings, length, contain_I=True):\n",
    "    if contain_I:\n",
    "        characters = ['I', 'X', 'Y', 'Z']\n",
    "    else:\n",
    "        characters = ['X', 'Y', 'Z']\n",
    "    generated_strings = []\n",
    "    assert num_strings < len(characters) ** length, 'too much strings to generate'\n",
    "    for _ in range(num_strings):\n",
    "        while True:\n",
    "            random_string = ''.join(np.random.choice(characters) for _ in range(length))\n",
    "            if random_string != 'I' * length and random_string not in generated_strings:\n",
    "                generated_strings.append(random_string)\n",
    "                break\n",
    "    return generated_strings\n",
    "\n",
    "def generate_random_01_strings(num_strings, length):\n",
    "    characters = ['0', '1']\n",
    "    generated_strings = []\n",
    "    assert num_strings < 2 ** length, 'too much strings to generate'\n",
    "    for _ in range(num_strings):\n",
    "        while True:\n",
    "            random_string = ''.join(np.random.choice(characters) for _ in range(length))\n",
    "            if random_string != '0' * length and random_string not in generated_strings:\n",
    "                generated_strings.append(random_string)\n",
    "                break\n",
    "    return generated_strings\n",
    "\n",
    "def generate_uv_Pauli_matrix(u_vec, v_vec):\n",
    "    uv_map = {\n",
    "        '00':'I', '01':'Z', '10':'X', '11':'Y'\n",
    "    }\n",
    "    Pauli_string = ''\n",
    "    for u, v in zip(u_vec, v_vec):\n",
    "        Pauli_char = uv_map.get(str(u) + str(v))\n",
    "        if Pauli_char is None:\n",
    "            raise ValueError('u or v list contains elements neither 0 or 1')\n",
    "        else:\n",
    "            Pauli_string += Pauli_char\n",
    "    return Pauli_string\n",
    "\n",
    "def generate_all_binary(length):\n",
    "    all_strings = itertools.product('01', repeat=length)\n",
    "    result = [''.join(s) for s in all_strings if '1' in s]\n",
    "    return result\n",
    "\n",
    "def generate_Pauli_expectations(dm, obsv):\n",
    "    return np.trace(dm @ Pauli(obsv).to_matrix()).real\n",
    "\n",
    "def get_trace_norm(dm):\n",
    "    return np.sum(np.linalg.svd(dm, compute_uv=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_Pauli_strings(num_strings, num_qubits, pattern='balanced'):\n",
    "    assert pattern in ['balanced', 'pro_I', 'pro_XYZ', 'uv_pair'], 'please choose pattern from: balanced, pro_I, pro_XYZ, uv_pair'\n",
    "    generated_strings = []\n",
    "    characters = ['X', 'Y', 'Z', 'I']\n",
    "    assert 0 < num_strings <= 4 ** num_qubits - 1, 'too much or too few strings to generate'\n",
    "    if pattern == 'balanced':\n",
    "        for _ in range(num_strings):\n",
    "            while True:\n",
    "                random_string = ''.join(np.random.choice(characters) for _ in range(num_qubits))\n",
    "                if random_string != 'I' * num_qubits and random_string not in generated_strings:\n",
    "                    generated_strings.append(random_string)\n",
    "                    break\n",
    "        return generated_strings\n",
    "    if pattern == 'uv_pair':\n",
    "        uv_map = {'00':'I', '01':'Z', '10':'X', '11':'Y'}\n",
    "        whole, remain = num_strings // 2 ** (num_qubits), num_strings % 2 ** (num_qubits)\n",
    "        if whole > 0:\n",
    "            v_lst = [format(i, f'0{num_qubits}b') for i in range(2 ** num_qubits)]\n",
    "            u_lst = np.random.choice([format(i, f'0{num_qubits}b') for i in range(1, 2 ** num_qubits)], whole, replace=False).tolist()\n",
    "            for u, v in list(itertools.product(u_lst, v_lst)):\n",
    "                generated_strings.append(''.join([uv_map[u_char + v_char] for u_char, v_char in zip(u, v)]))\n",
    "        if remain > 0:\n",
    "            u_lst = ['0' * num_qubits]\n",
    "            v_lst = np.random.choice([format(i, f'0{num_qubits}b') for i in range(1, 2 ** num_qubits)], remain, replace=False).tolist()\n",
    "            for u, v in list(itertools.product(u_lst, v_lst)):\n",
    "                generated_strings.append(''.join([uv_map[u_char + v_char] for u_char, v_char in zip(u, v)]))\n",
    "        return generated_strings\n",
    "    all_strings = generate_random_Pauli_strings(4 ** num_qubits - 1, num_qubits, pattern='balanced')\n",
    "    grouped = dict()\n",
    "    for i in range(num_qubits):\n",
    "        grouped[i] = []\n",
    "    for string in all_strings:\n",
    "        grouped[string.count('I')].append(string)\n",
    "    if pattern == 'pro_I':\n",
    "        i = num_qubits - 1\n",
    "        while len(generated_strings) < num_strings:\n",
    "            if num_strings - len(generated_strings) >= len(grouped[i]):\n",
    "                generated_strings += grouped[i]\n",
    "            else:\n",
    "                generated_strings += np.random.choice(grouped[i], num_strings - len(generated_strings), replace=True).tolist()\n",
    "            i -= 1\n",
    "        return generated_strings\n",
    "    if pattern == 'pro_XYZ':\n",
    "        i = 0\n",
    "        while len(generated_strings) < num_strings:\n",
    "            if num_strings - len(generated_strings) >= len(grouped[i]):\n",
    "                generated_strings += grouped[i]\n",
    "            else:\n",
    "                generated_strings += np.random.choice(grouped[i], num_strings - len(generated_strings), replace=True).tolist()\n",
    "            i += 1\n",
    "        return generated_strings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_Pauli_expectations(dm, obsv, num_samples, simulation=False):\n",
    "    num_samples = int(num_samples)\n",
    "    if simulation: # simulate the process of sampling\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        prob_p1 = (1 + exp) / 2\n",
    "        prob_m1 = 1 - prob_p1\n",
    "        samples = np.random.choice([+1, -1], size=num_samples, p=[prob_p1, prob_m1])\n",
    "        return np.mean(samples)\n",
    "    else: # use the approximate distribution instead\n",
    "        exp = np.real(np.trace(dm @ Pauli(obsv).to_matrix()))\n",
    "        num_samples_root = num_samples ** .5\n",
    "        std_dev = (1 - exp ** 2) ** .5 / num_samples_root\n",
    "        return np.random.normal(exp, std_dev)\n",
    "    \n",
    "def get_partial_trace(dm, subsystems):\n",
    "    return partial_trace(dm, subsystems).data\n",
    "\n",
    "def get_von_neumann_entropy(dm, r=None):\n",
    "    # if not np.allclose(dm, dm.conj().T):\n",
    "    #     raise ValueError(\"The density matrix must be Hermitian.\")\n",
    "    if r is None:\n",
    "        eigenvalues = np.linalg.eigvalsh(dm)\n",
    "        eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "        entropy = - np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    else:\n",
    "        eigenvalues = np.linalg.eigvalsh(dm)\n",
    "        eigenvalues = np.partition(eigenvalues, -r)[-r:]\n",
    "        entropy = - np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    return entropy\n",
    "\n",
    "def get_TMI(dm, r=None):\n",
    "    dm_s = get_partial_trace(dm, [1, 2])\n",
    "    dm_m1 = get_partial_trace(dm, [0, 2])\n",
    "    dm_m2 = get_partial_trace(dm, [1, 2])\n",
    "    dm_m = get_partial_trace(dm, [0])\n",
    "    dm_sm1 = get_partial_trace(dm, [2])\n",
    "    dm_sm2 = get_partial_trace(dm, [1])\n",
    "    i2_sm1 = get_von_neumann_entropy(dm_s, r) + get_von_neumann_entropy(dm_m1, r) - get_von_neumann_entropy(dm_sm1, r)\n",
    "    i2_sm2 = get_von_neumann_entropy(dm_s, r) + get_von_neumann_entropy(dm_m2, r) - get_von_neumann_entropy(dm_sm2, r)\n",
    "    i2_sm = get_von_neumann_entropy(dm_s, r) + get_von_neumann_entropy(dm_m, r) - get_von_neumann_entropy(dm, r)\n",
    "    return i2_sm1 + i2_sm2 - i2_sm\n",
    "\n",
    "def regularize(dm):\n",
    "    dm /= np.trace(dm)\n",
    "    dm = (dm + dm.conj().T) / 2\n",
    "    return dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(dm, num_qubits, obsv, expct, tol=1e-5):\n",
    "    true_TMI = get_TMI(dm)\n",
    "    while not np.all(np.array([np.abs(np.trace(dm @ Pauli(o).to_matrix()) - e) <= 1e-5 for o, e in zip(obsv, expct)])):\n",
    "        tol *= 10 ** .25\n",
    "    def optimize(dim, obsv, expct, tol=1e-5):\n",
    "        sigma = cp.Variable((dim, dim), complex=True)\n",
    "        objective = cp.Minimize(cp.abs(5 * cp.norm(sigma, 'nuc') + 0 * cp.norm(sigma, 'fro') ** 2))\n",
    "        constraints = [cp.trace(sigma) == 1]\n",
    "        for o, e in zip(obsv, expct):\n",
    "            constraints.append(cp.abs(cp.trace(sigma @ Pauli(o).to_matrix()) - e) <= tol)\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        if problem.status not in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n",
    "            raise ValueError(f\"Optimization failed with {len(obsv)} observables\")\n",
    "        return sigma.value\n",
    "    try: \n",
    "        sigma = optimize(2 ** num_qubits, obsv, expct)\n",
    "        sigma = regularize(sigma)\n",
    "    except ValueError:\n",
    "        estm_TMI = 0\n",
    "    estm_TMI = get_TMI(sigma)\n",
    "    err = (estm_TMI - true_TMI) / true_TMI\n",
    "    return estm_TMI, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(dm, num_qubits, obsv, expct, tol=1e-5):\n",
    "    true_TMI = get_TMI(dm)\n",
    "    while not np.all(np.array([np.abs(np.trace(dm @ Pauli(o).to_matrix()) - e) <= 1e-5 for o, e in zip(obsv, expct)])):\n",
    "        tol *= 10 ** .25\n",
    "    def optimize(dim, obsv, expct, tol=1e-5):\n",
    "        sigma = cp.Variable((dim, dim), complex=True)\n",
    "        objective = cp.Minimize(cp.sum([cp.abs(cp.trace(sigma @ Pauli(o).to_matrix()) - e) ** 2 for o, e in zip(obsv, expct)]) + len(obsv) * cp.norm(sigma, 'nuc'))\n",
    "        constraints = [sigma >> 0, cp.trace(sigma) == 1]\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        if problem.status not in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n",
    "            raise ValueError(f\"Optimization failed with {len(obsv)} observables\")\n",
    "        return sigma.value\n",
    "    try: \n",
    "        sigma = optimize(2 ** num_qubits, obsv, expct)\n",
    "        sigma = regularize(sigma)\n",
    "    except ValueError:\n",
    "        estm_TMI = 0\n",
    "    estm_TMI = get_TMI(sigma)\n",
    "    err = (estm_TMI - true_TMI) / true_TMI\n",
    "    return estm_TMI, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "num_samples = 1e12\n",
    "pmax = np.array([.90, .93, .96, .99])\n",
    "num_observables = np.arange(24, 48, 2)\n",
    "states_fidelities = [generate_dm(num_qubits, 5, prime_prob=p, compute_fidelity=True) for p in pmax]\n",
    "states, fidelities = [s_f[0] for s_f in states_fidelities], [s_f[1] for s_f in states_fidelities]\n",
    "all_observables = [generate_random_Pauli_strings(num_obs, num_qubits, contain_I=True) for num_obs in num_observables]\n",
    "TMIs = [get_TMI(s) for s in states]\n",
    "all_data = dict()\n",
    "for i in range(4):\n",
    "    state, key = states[i], str(i)\n",
    "    all_data[key] = {'TMI' : [], 'err' : []}\n",
    "    all_expectations = [[estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables] for observables in all_observables]\n",
    "    for j in range(len(num_observables)):\n",
    "        num_obs = num_observables[j]\n",
    "        observables = all_observables[j]\n",
    "        expectations = all_expectations[j]\n",
    "        estm_TMIs, errs = [], []\n",
    "        display(f\"now experimenting: index {i}, measurements {num_obs}\")\n",
    "        for _ in range(50):\n",
    "            estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-6)\n",
    "            estm_TMIs.append(estm_TMI)\n",
    "            errs.append(err)\n",
    "        all_data[key]['TMI'].append(np.mean(estm_TMIs))\n",
    "        all_data[key]['err'].append(np.mean(errs))\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "num_qubits = 3\n",
    "num_samples = 1e12\n",
    "nums_observables = np.arange(25, 64, 2)\n",
    "pmax = np.array([.90, .93, .96])\n",
    "pmax_label=['90', '93', '96']\n",
    "for i in range(3):\n",
    "    p, plabel = pmax[i], pmax_label[i]\n",
    "    errs_data = dict()\n",
    "    for num_observables in nums_observables:\n",
    "        errs = []\n",
    "        for _ in range(50):\n",
    "            state = generate_dm(3, 5, prime_prob=p)\n",
    "            observables = generate_random_Pauli_strings(num_observables, 3, contain_I=True)\n",
    "            expectations = [estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables]\n",
    "            estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-7)\n",
    "            errs.append(err)\n",
    "        errs_data[int(num_observables)] = errs\n",
    "    name = 'tracenorm_balanced_' + plabel + '.json'\n",
    "    with open(name, 'w') as file:\n",
    "        json.dump(errs_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "num_qubits = 3\n",
    "num_samples = 1e12\n",
    "nums_observables = np.arange(25, 64, 2)\n",
    "pmax = np.array([.99])\n",
    "pmax_label=['99']\n",
    "patterns = ['balanced']\n",
    "for pattern in patterns:\n",
    "    for i in range(4):\n",
    "        p, plabel = pmax[i], pmax_label[i]\n",
    "        errs_data = dict()\n",
    "        for num_observables in nums_observables:\n",
    "            errs = []\n",
    "            display(f\"now computing: plabel={plabel}, pattern={pattern}, num_observables={num_observables}\")\n",
    "            for _ in range(50):\n",
    "                state = generate_dm(3, 5, prime_prob=p)\n",
    "                observables = generate_random_Pauli_strings(num_observables, 3, pattern)\n",
    "                expectations = [estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables]\n",
    "                estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-7)\n",
    "                errs.append(err)\n",
    "            errs_data[int(num_observables)] = errs\n",
    "            clear_output()\n",
    "        name = 'tracenorm_' + pattern + '_' + plabel + '.json'\n",
    "        with open(name, 'w') as file:\n",
    "            json.dump(errs_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "patterns = ['balanced', 'pro_I', 'pro_XYZ', 'uv_pair']\n",
    "methods = ['tracenorm']\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    for pattern in patterns:\n",
    "        path = r'von Neumann Entropy\\output\\fig01\\\\' + method + '_' + pattern + '_99.json'\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        nums_observables, means, lower_bounds, upper_bounds = [], [], [], []\n",
    "        for num_observables, errors in data.items():\n",
    "            if int(num_observables) > 37:\n",
    "                nums_observables.append(int(num_observables))\n",
    "                errors = np.abs(np.array(errors))\n",
    "                lower_bound = np.percentile(errors, 0)  \n",
    "                upper_bound = np.percentile(errors, 95) \n",
    "                filtered_array = errors[(errors >= lower_bound) & (errors <= upper_bound)]\n",
    "                means.append(np.mean(filtered_array))\n",
    "                lower_bounds.append(lower_bound)\n",
    "                upper_bounds.append(upper_bound)\n",
    "        means = np.array(means)\n",
    "        lower_bounds = np.array(lower_bounds)\n",
    "        upper_bounds = np.array(upper_bounds)\n",
    "        error_bars = np.vstack((means - lower_bounds, upper_bounds - means))\n",
    "\n",
    "        axs[0, 0].plot(nums_observables, means, linewidth=1, label=pattern)\n",
    "        # plt.errorbar(nums_observables, means, yerr=error_bars, fmt='o', capsize=2, capthick=1)\n",
    "    \n",
    "axs[0, 0].set_xlabel('Number of Observables')\n",
    "axs[0, 0].set_ylabel('Mean Error (' + r'$95\\%$' + 'Range)')\n",
    "axs[0, 0].set_ylim([0, .35])\n",
    "axs[0, 0].set_title('Mean Error for State with ' + r'$p_m=0.99$')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "for method in methods:\n",
    "    for pattern in patterns:\n",
    "        path = r'von Neumann Entropy\\output\\fig01\\\\' + method + '_' + pattern + '_96.json'\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        nums_observables, means, lower_bounds, upper_bounds = [], [], [], []\n",
    "        for num_observables, errors in data.items():\n",
    "            if int(num_observables) > 37:\n",
    "                nums_observables.append(int(num_observables))\n",
    "                errors = np.abs(np.array(errors))\n",
    "                lower_bound = np.percentile(errors, 0)  \n",
    "                upper_bound = np.percentile(errors, 95) \n",
    "                filtered_array = errors[(errors >= lower_bound) & (errors <= upper_bound)]\n",
    "                means.append(np.mean(filtered_array))\n",
    "                lower_bounds.append(lower_bound)\n",
    "                upper_bounds.append(upper_bound)\n",
    "        means = np.array(means)\n",
    "        lower_bounds = np.array(lower_bounds)\n",
    "        upper_bounds = np.array(upper_bounds)\n",
    "        error_bars = np.vstack((means - lower_bounds, upper_bounds - means))\n",
    "\n",
    "        axs[0, 1].plot(nums_observables, means, linewidth=1, label=pattern)\n",
    "        # plt.errorbar(nums_observables, means, yerr=error_bars, fmt='o', capsize=2, capthick=1)\n",
    "    \n",
    "axs[0, 1].set_xlabel('Number of Observables')\n",
    "axs[0, 1].set_ylabel('Mean Error (' + r'$95\\%$' + 'Range)')\n",
    "axs[0, 1].set_ylim([0, .35])\n",
    "axs[0, 1].set_title('Mean Error for State with ' + r'$p_m=0.96$')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "for method in methods:\n",
    "    for pattern in patterns:\n",
    "        path = r'von Neumann Entropy\\output\\fig01\\\\' + method + '_' + pattern + '_93.json'\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        nums_observables, means, lower_bounds, upper_bounds = [], [], [], []\n",
    "        for num_observables, errors in data.items():\n",
    "            if int(num_observables) > 37:\n",
    "                nums_observables.append(int(num_observables))\n",
    "                errors = np.abs(np.array(errors))\n",
    "                lower_bound = np.percentile(errors, 0)  \n",
    "                upper_bound = np.percentile(errors, 95) \n",
    "                filtered_array = errors[(errors >= lower_bound) & (errors <= upper_bound)]\n",
    "                means.append(np.mean(filtered_array))\n",
    "                lower_bounds.append(lower_bound)\n",
    "                upper_bounds.append(upper_bound)\n",
    "        means = np.array(means)\n",
    "        lower_bounds = np.array(lower_bounds)\n",
    "        upper_bounds = np.array(upper_bounds)\n",
    "        error_bars = np.vstack((means - lower_bounds, upper_bounds - means))\n",
    "\n",
    "        axs[1, 0].plot(nums_observables, means, linewidth=1, label=pattern)\n",
    "        # plt.errorbar(nums_observables, means, yerr=error_bars, fmt='o', capsize=2, capthick=1)\n",
    "    \n",
    "axs[1, 0].set_xlabel('Number of Observables')\n",
    "axs[1, 0].set_ylabel('Mean Error (' + r'$95\\%$' + 'Range)')\n",
    "axs[1, 0].set_ylim([0, .35])\n",
    "axs[1, 0].set_title('Mean Error for State with ' + r'$p_m=0.93$')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "for method in methods:\n",
    "    for pattern in patterns:\n",
    "        path = r'von Neumann Entropy\\output\\fig01\\\\' + method + '_' + pattern + '_90.json'\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        nums_observables, means, lower_bounds, upper_bounds = [], [], [], []\n",
    "        for num_observables, errors in data.items():\n",
    "            if int(num_observables) > 37:\n",
    "                nums_observables.append(int(num_observables))\n",
    "                errors = np.abs(np.array(errors))\n",
    "                lower_bound = np.percentile(errors, 0)  \n",
    "                upper_bound = np.percentile(errors, 95) \n",
    "                filtered_array = errors[(errors >= lower_bound) & (errors <= upper_bound)]\n",
    "                means.append(np.mean(filtered_array))\n",
    "                lower_bounds.append(lower_bound)\n",
    "                upper_bounds.append(upper_bound)\n",
    "        means = np.array(means)\n",
    "        lower_bounds = np.array(lower_bounds)\n",
    "        upper_bounds = np.array(upper_bounds)\n",
    "        error_bars = np.vstack((means - lower_bounds, upper_bounds - means))\n",
    "\n",
    "        axs[1, 1].plot(nums_observables, means, linewidth=1, label=pattern)\n",
    "        # plt.errorbar(nums_observables, means, yerr=error_bars, fmt='o', capsize=2, capthick=1)\n",
    "    \n",
    "axs[1, 1].set_xlabel('Number of Observables')\n",
    "axs[1, 1].set_ylabel('Mean Error (' + r'$95\\%$' + 'Range)')\n",
    "axs[1, 1].set_ylim([0, .35])\n",
    "axs[1, 1].set_title('Mean Error for State with ' + r'$p_m=0.90$')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True)\n",
    "fig.suptitle('Mean Error for Nearly Pure States, $r=5$, with $10^{12}$ samples', fontsize=24)\n",
    "plt.subplots_adjust(top=.92)\n",
    "plt.savefig('fig01.png', dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "for _ in range(100):\n",
    "    state = generate_dm(3, 1, prime_prob=1)\n",
    "    observables = generate_random_Pauli_strings(49, 3, 'uv_pair')\n",
    "    expectations = [estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables]\n",
    "    estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-7)\n",
    "    errs.append(abs(err))\n",
    "errs = np.array(errs)\n",
    "# upper_bound = np.percentile(errors, 95)\n",
    "# errs = errs[errs < upper_bound]\n",
    "np.mean(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = dict()\n",
    "ranks = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "for r in ranks:\n",
    "    errs = []\n",
    "    if r == 1:\n",
    "        pmax = 1\n",
    "    else:\n",
    "        pamx = .93\n",
    "    for _ in range(100):\n",
    "        state = generate_dm(3, r, prime_prob=pmax)\n",
    "        observables = generate_random_Pauli_strings(49, 3, 'uv_pair')\n",
    "        expectations = [estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables]\n",
    "        estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-7)\n",
    "        errs.append(abs(err))\n",
    "    errs = np.array(errs)\n",
    "    # upper_bound = np.percentile(errs, 95)\n",
    "    # errs = errs[errs < upper_bound]\n",
    "    errors[str(r)] = errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data, std_dev_data = [], []\n",
    "for errs in errors.values():\n",
    "    upper_bound = np.percentile(errs, 95)\n",
    "    errs = errs[errs < upper_bound]\n",
    "    mean_data.append(np.mean(errs))\n",
    "    std_dev_data.append(np.std(errs))\n",
    "mean_data = np.array(mean_data)\n",
    "std_dev_data = np.array(std_dev_data)\n",
    "plt.plot(ranks, mean_data, linewidth=2, color='orange')\n",
    "plt.errorbar(ranks, mean_data, yerr=std_dev_data, color='red', fmt='o', label='Data with std dev error bars')\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('Mean Error (' + r'$95\\%$' + 'Range)')\n",
    "plt.title('Mean Error for $p_m=0.93$ states, with $10^{12}$ samples')\n",
    "plt.savefig('fig02.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros([3, 3])\n",
    "num_samples = 1e12\n",
    "num_qubits = 3\n",
    "i, j, k = 0, 0, 0\n",
    "while True:\n",
    "    state = generate_dm(3, 3, prime_prob=.99)\n",
    "    observables = generate_random_Pauli_strings(49, 3, 'uv_pair')\n",
    "    expectations = [estimate_Pauli_expectations(state, obsv, num_samples) for obsv in observables]\n",
    "    estm_TMI, err = trial(state, num_qubits, observables, expectations, tol=1e-7)\n",
    "    if abs(estm_TMI) < .01:\n",
    "        i += 1\n",
    "        if i <= 1000:\n",
    "            if err < .02:\n",
    "                table[0, 0] += 1\n",
    "            elif .02 <= err <= .2:\n",
    "                table[0, 1] += 1\n",
    "            else:\n",
    "                table[0, 2] += 1\n",
    "    elif .01 <= abs(estm_TMI) <= .05:\n",
    "        j += 1\n",
    "        if j <= 1000:\n",
    "            if err < .02:\n",
    "                table[1, 0] += 1\n",
    "            elif .02 <= err <= .2:\n",
    "                table[1, 1] += 1\n",
    "            else:\n",
    "                table[1, 2] += 1\n",
    "    else:\n",
    "        k += 1\n",
    "        if k <= 1000:\n",
    "            if err < .02:\n",
    "                table[2, 0] += 1\n",
    "            elif .02 <= err <= .2:\n",
    "                table[2, 1] += 1\n",
    "            else:\n",
    "                table[2, 2] += 1\n",
    "    if i >= 1000 and j >= 1000 and k >= 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
